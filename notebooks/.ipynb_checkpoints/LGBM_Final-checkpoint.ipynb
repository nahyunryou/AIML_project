{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb0d1f7-fdb4-48b6-9fcd-f7d9f579c99a",
   "metadata": {},
   "source": [
    "# LGBM - Only New Columns (No Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728b35-a6dd-4327-9715-8bfa8f5c5996",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83ce26c-3dfd-40e2-be26-4c8779413f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996df80-8d54-4e82-bc40-61b2199a8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_month</th>\n",
       "      <th>birth_week</th>\n",
       "      <th>ages_employed</th>\n",
       "      <th>employ_month</th>\n",
       "      <th>employ_week</th>\n",
       "      <th>ages_unemployed</th>\n",
       "      <th>unemploy_month</th>\n",
       "      <th>unemploy_week</th>\n",
       "      <th>income_family</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>F13899202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>F11380247500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>M19087450000.0Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>F15088202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78750.0</td>\n",
       "      <td>F15037157500.0State servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  income_total           income_type  \\\n",
       "0           0      F   N       N      202500.0  Commercial associate   \n",
       "1           1      F   N       Y      247500.0  Commercial associate   \n",
       "2           2      M   Y       Y      450000.0               Working   \n",
       "3           3      F   N       Y      202500.0  Commercial associate   \n",
       "4           4      F   Y       Y      157500.0         State servant   \n",
       "\n",
       "                        edu_type     family_type           house_type  \\\n",
       "0               Higher education         Married  Municipal apartment   \n",
       "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
       "2               Higher education         Married    House / apartment   \n",
       "3  Secondary / secondary special         Married    House / apartment   \n",
       "4               Higher education         Married    House / apartment   \n",
       "\n",
       "   work_phone  ...  birth_month  birth_week ages_employed  employ_month  \\\n",
       "0           0  ...          7.0         1.0            12           0.0   \n",
       "1           0  ...          7.0         1.0             4           3.0   \n",
       "2           0  ...          0.0         2.0            12           3.0   \n",
       "3           0  ...         10.0         3.0             5           9.0   \n",
       "4           0  ...          9.0         0.0             5          10.0   \n",
       "\n",
       "   employ_week  ages_unemployed  unemploy_month  unemploy_week  income_family  \\\n",
       "0          0.0               25             6.0            0.0       101250.0   \n",
       "1          0.0               26             4.0            1.0        82500.0   \n",
       "2          1.0               40             8.0            1.0       225000.0   \n",
       "3          2.0               35             1.0            0.0       101250.0   \n",
       "4          0.0               35            11.0            3.0        78750.0   \n",
       "\n",
       "                                 CODE  \n",
       "0  F13899202500.0Commercial associate  \n",
       "1  F11380247500.0Commercial associate  \n",
       "2               M19087450000.0Working  \n",
       "3  F15088202500.0Commercial associate  \n",
       "4         F15037157500.0State servant  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"../data/processed_train_code.csv\")\n",
    "test_df=pd.read_csv(\"../data/processed_test_code.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5ec4a1-f345-43a0-96cb-6df792499ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26451 entries, 0 to 26450\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         26451 non-null  int64  \n",
      " 1   gender             26451 non-null  object \n",
      " 2   car                26451 non-null  object \n",
      " 3   reality            26451 non-null  object \n",
      " 4   income_total       26451 non-null  float64\n",
      " 5   income_type        26451 non-null  object \n",
      " 6   edu_type           26451 non-null  object \n",
      " 7   family_type        26451 non-null  object \n",
      " 8   house_type         26451 non-null  object \n",
      " 9   work_phone         26451 non-null  int64  \n",
      " 10  home_phone         26451 non-null  int64  \n",
      " 11  email              26451 non-null  int64  \n",
      " 12  occup_type         26451 non-null  object \n",
      " 13  family_size        26451 non-null  float64\n",
      " 14  begin_month        26451 non-null  float64\n",
      " 15  credit             26451 non-null  float64\n",
      " 16  days_unemployed    26451 non-null  int64  \n",
      " 17  income_unemployed  26451 non-null  float64\n",
      " 18  Age                26451 non-null  int64  \n",
      " 19  birth_month        26451 non-null  float64\n",
      " 20  birth_week         26451 non-null  float64\n",
      " 21  ages_employed      26451 non-null  int64  \n",
      " 22  employ_month       26451 non-null  float64\n",
      " 23  employ_week        26451 non-null  float64\n",
      " 24  ages_unemployed    26451 non-null  int64  \n",
      " 25  unemploy_month     26451 non-null  float64\n",
      " 26  unemploy_week      26451 non-null  float64\n",
      " 27  income_family      26451 non-null  float64\n",
      " 28  CODE               26451 non-null  object \n",
      "dtypes: float64(12), int64(8), object(9)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153ab41-bd52-4f6b-b942-bddacc461c0b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb9b5-1f99-43e7-95da-b1aa2e3f4984",
   "metadata": {},
   "source": [
    "### Numerical Data: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ecd7f4-7d09-4121-9beb-6a6113cc3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data_scale(train_df, test_df, scaling_cols=None):\n",
    "    \n",
    "    scaling_cols = ['income_total', 'family_size', 'days_unemployed', 'income_unemployed', 'Age', 'birth_month', 'birth_week', 'ages_employed', 'employ_month', 'employ_week', 'ages_unemployed', 'unemploy_month', 'unemploy_week', 'income_family']\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "    train_scaled = std_scaler.transform(train_df[scaling_cols])\n",
    "    test_scaled = std_scaler.transform(test_df[scaling_cols]) # Apply to the test set using the scaler that was fitted with train data!!\n",
    "\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=scaling_cols)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=scaling_cols)\n",
    "\n",
    "    train_scaled.shape, test_scaled.shape\n",
    "    \n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40509c9-b9a2-483e-b7de-2a42a47f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = num_data_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7082e6-5b3b-47b5-836e-1fab433a3caa",
   "metadata": {},
   "source": [
    "### Categorical Data: One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fdd30d0-5a85-48d5-8983-2fe166a18648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_encode(train_df, test_df, onehot_cols=None):\n",
    "    \n",
    "    onehot_cols = ['gender','car','reality','income_type','edu_type','family_type','house_type','occup_type','work_phone','home_phone','email', 'begin_month']\n",
    "    data = pd.concat([train_df[onehot_cols], test_df[onehot_cols]]) # One-hot encoding using the combination of train and test data\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    # data separation\n",
    "    data = data.reset_index(drop=True)\n",
    "    train_encoded = data.loc[:train_df.shape[0]-1]\n",
    "    test_encoded = data.loc[train_df.shape[0]:]\n",
    "    test_encoded = test_encoded.reset_index(drop=True)\n",
    "    \n",
    "    train_encoded.shape, test_encoded.shape\n",
    "    \n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53b70e7-438a-4bab-bc0e-e58588a1eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = cat_data_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be44a5-9009-426b-85e3-794722ec960b",
   "metadata": {},
   "source": [
    "### Merge scaled numerical data with encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f1fb29-0810-4ac7-b4d9-343a68ac191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded):\n",
    "    \n",
    "    Train = pd.concat([train_scaled,train_encoded],axis=1)\n",
    "    Train = pd.concat([Train,train_df['credit']],axis=1)\n",
    "\n",
    "    Test = pd.concat([test_scaled,test_encoded],axis=1)\n",
    "\n",
    "    Train.shape, Test.shape\n",
    "    \n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e80a91d-a145-46f8-810d-3c027739f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570651c1-6d02-483e-952c-90fabd5a5f7a",
   "metadata": {},
   "source": [
    "## Split Training and Validation set#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4783507-8f94-4764-b221-a80c55f126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Train.drop(['credit'], axis=1)\n",
    "y_data = Train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e24cde9-08ec-48d9-ad54-6e50410f7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00366b1b-d2ac-4475-8d9c-d8bfbbfec8c3",
   "metadata": {},
   "source": [
    "## Train with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6587a936-ed74-4168-82af-cd911c2298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "414114a2-4ba9-49d7-a094-cf74926e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trn, tst, cv = 5):\n",
    "    \n",
    "    tst_preds = []\n",
    "    vld_preds = []\n",
    "    feats_importance = np.zeros(tst.shape[1])    \n",
    "    for n, (trn_idx, vld_idx) in enumerate(StratifiedKFold(cv).split(trn.drop('credit', axis = 1).values, trn['credit'].values)):\n",
    "        print(f\"{n+1}/{cv}th fold..........\")        \n",
    "        X_trn = trn.loc[trn_idx, :].drop('credit', axis = 1)\n",
    "        X_vld = trn.loc[vld_idx, :].drop('credit', axis = 1)\n",
    "        y_trn = trn.loc[trn_idx, 'credit'].values\n",
    "        y_vld = trn.loc[vld_idx, 'credit'].values\n",
    "        \n",
    "        model.fit(\n",
    "            X_trn, y_trn,\n",
    "            eval_set = [(X_trn, y_trn), (X_vld, y_vld)],\n",
    "            verbose = 500, early_stopping_rounds = 30\n",
    "        )    \n",
    "        vld_preds.append(log_loss(y_vld, model.predict_proba(X_vld)))        \n",
    "        \n",
    "        tst_pred = model.predict_proba(tst)\n",
    "        tst_preds.append(tst_pred)\n",
    "        feats_importance += model.feature_importances_                        \n",
    "        \n",
    "    feats_importance = feats_importance / cv\n",
    "    feats_importance = pd.Series(data = feats_importance, index = tst.columns)\n",
    "\n",
    "    print('mlogloss: ', np.mean(vld_preds))\n",
    "    return tst_preds, feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e92776-cb6f-4e8e-9538-2f8eebfa5f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.505877\tvalid_1's multi_logloss: 0.707524\n",
      "2/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506251\tvalid_1's multi_logloss: 0.694409\n",
      "3/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504711\tvalid_1's multi_logloss: 0.715838\n",
      "4/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506196\tvalid_1's multi_logloss: 0.696062\n",
      "5/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.507217\tvalid_1's multi_logloss: 0.698763\n",
      "6/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.5043\tvalid_1's multi_logloss: 0.707221\n",
      "7/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506672\tvalid_1's multi_logloss: 0.704681\n",
      "8/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504059\tvalid_1's multi_logloss: 0.717582\n",
      "9/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504313\tvalid_1's multi_logloss: 0.713331\n",
      "10/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.505444\tvalid_1's multi_logloss: 0.708977\n",
      "mlogloss:  0.701361456806392\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**lgbm_params), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda7ef96-6d16-4fa3-886d-506608cdd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_total                        8017.0\n",
       "family_size                         1556.6\n",
       "days_unemployed                    14069.6\n",
       "income_unemployed                  15802.4\n",
       "Age                                 8853.8\n",
       "                                    ...   \n",
       "occup_type_Realty agents               3.9\n",
       "occup_type_Sales staff               597.3\n",
       "occup_type_Secretaries                54.3\n",
       "occup_type_Security staff            174.8\n",
       "occup_type_Waiters/barmen staff       81.6\n",
       "Length: 64, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_im_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec158ef-669e-4409-acd2-d97dc848180f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3f66bc-3ddf-45b4-96f2-f8d09a980287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'verbose': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
    "    }\n",
    "    model = LGBMClassifier(**param)\n",
    "    lgb_model = model.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=0, early_stopping_rounds=25)\n",
    "\n",
    "    score = cross_val_score(model, x_data, y_data, cv=5, scoring=\"neg_log_loss\")\n",
    "    log_loss = score.mean()\n",
    "\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b803ff9-9608-48e5-a9ad-b6335022c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 17:20:22,251]\u001b[0m A new study created in memory with name: no-name-456b8119-8de3-4ab1-895d-7b3e5053e97c\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:20:53,474]\u001b[0m Trial 0 finished with value: -0.8824223569432752 and parameters: {'max_depth': 5, 'learning_rate': 4.605630234796205e-07, 'n_estimators': 1548, 'min_child_samples': 66, 'subsample': 0.5882420283504455}. Best is trial 0 with value: -0.8824223569432752.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:21:14,196]\u001b[0m Trial 1 finished with value: -0.7973247496511402 and parameters: {'max_depth': 3, 'learning_rate': 0.003157574844163126, 'n_estimators': 2251, 'min_child_samples': 54, 'subsample': 0.5049876643096728}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:21:16,724]\u001b[0m Trial 2 finished with value: -0.882530333232965 and parameters: {'max_depth': 3, 'learning_rate': 3.7801607860063186e-07, 'n_estimators': 250, 'min_child_samples': 65, 'subsample': 0.4601457127759031}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:22:13,313]\u001b[0m Trial 3 finished with value: -0.8235561586289316 and parameters: {'max_depth': 6, 'learning_rate': 0.0003161829578192192, 'n_estimators': 2296, 'min_child_samples': 42, 'subsample': 0.84612092141778}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:23:27,217]\u001b[0m Trial 4 finished with value: -0.8824745816992147 and parameters: {'max_depth': 11, 'learning_rate': 1.453697682131156e-07, 'n_estimators': 2630, 'min_child_samples': 33, 'subsample': 0.45688452720427314}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:23:55,837]\u001b[0m Trial 5 finished with value: -0.8546753555578638 and parameters: {'max_depth': 15, 'learning_rate': 0.00018071090191879057, 'n_estimators': 1086, 'min_child_samples': 40, 'subsample': 0.6304434008736326}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:24:11,523]\u001b[0m Trial 6 finished with value: -0.8773395100681765 and parameters: {'max_depth': 5, 'learning_rate': 3.526269695615576e-05, 'n_estimators': 897, 'min_child_samples': 41, 'subsample': 0.4914171011579192}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:24:39,368]\u001b[0m Trial 7 finished with value: -0.813777208472126 and parameters: {'max_depth': 7, 'learning_rate': 0.0008272367416700086, 'n_estimators': 1177, 'min_child_samples': 91, 'subsample': 0.9865062960197898}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:25:05,609]\u001b[0m Trial 8 finished with value: -0.8825298822739616 and parameters: {'max_depth': 12, 'learning_rate': 8.593425591492479e-08, 'n_estimators': 1036, 'min_child_samples': 69, 'subsample': 0.468793937054017}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:25:11,997]\u001b[0m Trial 9 finished with value: -0.8744402436424412 and parameters: {'max_depth': 3, 'learning_rate': 6.617542114619483e-05, 'n_estimators': 786, 'min_child_samples': 42, 'subsample': 0.6403199537104163}. Best is trial 1 with value: -0.7973247496511402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.7973247496511402\n",
      "Best trial {'max_depth': 3, 'learning_rate': 0.003157574844163126, 'n_estimators': 2251, 'min_child_samples': 54, 'subsample': 0.5049876643096728}\n"
     ]
    }
   ],
   "source": [
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best Score:\",lgbm_study.best_value)\n",
    "print(\"Best trial\",lgbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c690524-f06e-497a-9f84-32ff34632f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameterization\n",
    "\n",
    "p_optuna = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.003157574844163126,\n",
    "    'n_estimators': 2251,\n",
    "    'min_child_samples': 54,\n",
    "    'subsample': 0.5049876643096728,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8442cb-89fa-4a0e-bb2a-33bfe5eee128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.810449\tvalid_1's multi_logloss: 0.808349\n",
      "[1000]\ttraining's multi_logloss: 0.798501\tvalid_1's multi_logloss: 0.800979\n",
      "[1500]\ttraining's multi_logloss: 0.791008\tvalid_1's multi_logloss: 0.797136\n",
      "[2000]\ttraining's multi_logloss: 0.785539\tvalid_1's multi_logloss: 0.794856\n",
      "2/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.810321\tvalid_1's multi_logloss: 0.812447\n",
      "[1000]\ttraining's multi_logloss: 0.799118\tvalid_1's multi_logloss: 0.80368\n",
      "[1500]\ttraining's multi_logloss: 0.791901\tvalid_1's multi_logloss: 0.798818\n",
      "[2000]\ttraining's multi_logloss: 0.786047\tvalid_1's multi_logloss: 0.796105\n",
      "3/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.809809\tvalid_1's multi_logloss: 0.81481\n",
      "[1000]\ttraining's multi_logloss: 0.798143\tvalid_1's multi_logloss: 0.806673\n",
      "[1500]\ttraining's multi_logloss: 0.79073\tvalid_1's multi_logloss: 0.803021\n",
      "[2000]\ttraining's multi_logloss: 0.784841\tvalid_1's multi_logloss: 0.801226\n",
      "4/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.810382\tvalid_1's multi_logloss: 0.811552\n",
      "[1000]\ttraining's multi_logloss: 0.799284\tvalid_1's multi_logloss: 0.802722\n",
      "[1500]\ttraining's multi_logloss: 0.792385\tvalid_1's multi_logloss: 0.798088\n",
      "[2000]\ttraining's multi_logloss: 0.78694\tvalid_1's multi_logloss: 0.794115\n",
      "5/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.809161\tvalid_1's multi_logloss: 0.817008\n",
      "[1000]\ttraining's multi_logloss: 0.79805\tvalid_1's multi_logloss: 0.808489\n",
      "[1500]\ttraining's multi_logloss: 0.790794\tvalid_1's multi_logloss: 0.803239\n",
      "[2000]\ttraining's multi_logloss: 0.785869\tvalid_1's multi_logloss: 0.800314\n",
      "6/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.8096\tvalid_1's multi_logloss: 0.81448\n",
      "[1000]\ttraining's multi_logloss: 0.797826\tvalid_1's multi_logloss: 0.807092\n",
      "[1500]\ttraining's multi_logloss: 0.790606\tvalid_1's multi_logloss: 0.803307\n",
      "[2000]\ttraining's multi_logloss: 0.784738\tvalid_1's multi_logloss: 0.800347\n",
      "7/10th fold..........\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**p_optuna), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe16e0-5abd-4777-8a23-c0b3b9e34f64",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05597f62-181b-426e-9dc1-185f5523a57e",
   "metadata": {},
   "source": [
    "**Manual: 0.7014** / Tuned: 0.7427"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2a657-6c79-46ed-94ab-34fd468093c9",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "### Base\n",
    "**Manual: 0.7525** / Tuned: 0.8015\n",
    "### Code\n",
    "**Manual: 0.7525** / Tuned: 0.7913\n",
    "### New\n",
    "\n",
    "### Code & New \n",
    "**Manual: 0.7019** / Tuned: 0.7427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890cfc-6c01-4b42-a03f-f2b8b5a65678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
