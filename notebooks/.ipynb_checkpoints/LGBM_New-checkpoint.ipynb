{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb0d1f7-fdb4-48b6-9fcd-f7d9f579c99a",
   "metadata": {},
   "source": [
    "# LGBM - Code&New"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728b35-a6dd-4327-9715-8bfa8f5c5996",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83ce26c-3dfd-40e2-be26-4c8779413f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996df80-8d54-4e82-bc40-61b2199a8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_month</th>\n",
       "      <th>birth_week</th>\n",
       "      <th>ages_employed</th>\n",
       "      <th>employ_month</th>\n",
       "      <th>employ_week</th>\n",
       "      <th>ages_unemployed</th>\n",
       "      <th>unemploy_month</th>\n",
       "      <th>unemploy_week</th>\n",
       "      <th>income_family</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>F13899202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>F11380247500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>M19087450000.0Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101250.0</td>\n",
       "      <td>F15088202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78750.0</td>\n",
       "      <td>F15037157500.0State servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  income_total           income_type  \\\n",
       "0           0      F   N       N      202500.0  Commercial associate   \n",
       "1           1      F   N       Y      247500.0  Commercial associate   \n",
       "2           2      M   Y       Y      450000.0               Working   \n",
       "3           3      F   N       Y      202500.0  Commercial associate   \n",
       "4           4      F   Y       Y      157500.0         State servant   \n",
       "\n",
       "                        edu_type     family_type           house_type  \\\n",
       "0               Higher education         Married  Municipal apartment   \n",
       "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
       "2               Higher education         Married    House / apartment   \n",
       "3  Secondary / secondary special         Married    House / apartment   \n",
       "4               Higher education         Married    House / apartment   \n",
       "\n",
       "   work_phone  ...  birth_month  birth_week ages_employed  employ_month  \\\n",
       "0           0  ...          7.0         1.0            12           0.0   \n",
       "1           0  ...          7.0         1.0             4           3.0   \n",
       "2           0  ...          0.0         2.0            12           3.0   \n",
       "3           0  ...         10.0         3.0             5           9.0   \n",
       "4           0  ...          9.0         0.0             5          10.0   \n",
       "\n",
       "   employ_week  ages_unemployed  unemploy_month  unemploy_week  income_family  \\\n",
       "0          0.0               25             6.0            0.0       101250.0   \n",
       "1          0.0               26             4.0            1.0        82500.0   \n",
       "2          1.0               40             8.0            1.0       225000.0   \n",
       "3          2.0               35             1.0            0.0       101250.0   \n",
       "4          0.0               35            11.0            3.0        78750.0   \n",
       "\n",
       "                                 CODE  \n",
       "0  F13899202500.0Commercial associate  \n",
       "1  F11380247500.0Commercial associate  \n",
       "2               M19087450000.0Working  \n",
       "3  F15088202500.0Commercial associate  \n",
       "4         F15037157500.0State servant  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"../data/processed_train_code.csv\")\n",
    "test_df=pd.read_csv(\"../data/processed_test_code.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5ec4a1-f345-43a0-96cb-6df792499ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26451 entries, 0 to 26450\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         26451 non-null  int64  \n",
      " 1   gender             26451 non-null  object \n",
      " 2   car                26451 non-null  object \n",
      " 3   reality            26451 non-null  object \n",
      " 4   income_total       26451 non-null  float64\n",
      " 5   income_type        26451 non-null  object \n",
      " 6   edu_type           26451 non-null  object \n",
      " 7   family_type        26451 non-null  object \n",
      " 8   house_type         26451 non-null  object \n",
      " 9   work_phone         26451 non-null  int64  \n",
      " 10  home_phone         26451 non-null  int64  \n",
      " 11  email              26451 non-null  int64  \n",
      " 12  occup_type         26451 non-null  object \n",
      " 13  family_size        26451 non-null  float64\n",
      " 14  begin_month        26451 non-null  float64\n",
      " 15  credit             26451 non-null  float64\n",
      " 16  days_unemployed    26451 non-null  int64  \n",
      " 17  income_unemployed  26451 non-null  float64\n",
      " 18  Age                26451 non-null  int64  \n",
      " 19  birth_month        26451 non-null  float64\n",
      " 20  birth_week         26451 non-null  float64\n",
      " 21  ages_employed      26451 non-null  int64  \n",
      " 22  employ_month       26451 non-null  float64\n",
      " 23  employ_week        26451 non-null  float64\n",
      " 24  ages_unemployed    26451 non-null  int64  \n",
      " 25  unemploy_month     26451 non-null  float64\n",
      " 26  unemploy_week      26451 non-null  float64\n",
      " 27  income_family      26451 non-null  float64\n",
      " 28  CODE               26451 non-null  object \n",
      "dtypes: float64(12), int64(8), object(9)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153ab41-bd52-4f6b-b942-bddacc461c0b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb9b5-1f99-43e7-95da-b1aa2e3f4984",
   "metadata": {},
   "source": [
    "### Numerical Data: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ecd7f4-7d09-4121-9beb-6a6113cc3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data_scale(train_df, test_df, scaling_cols=None):\n",
    "    \n",
    "    scaling_cols = ['income_total', 'family_size', 'days_unemployed', 'income_unemployed', 'Age', 'birth_month', 'birth_week', 'ages_employed', 'employ_month', 'employ_week', 'ages_unemployed', 'unemploy_month', 'unemploy_week', 'income_family']\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "    train_scaled = std_scaler.transform(train_df[scaling_cols])\n",
    "    test_scaled = std_scaler.transform(test_df[scaling_cols]) # Apply to the test set using the scaler that was fitted with train data!!\n",
    "\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=scaling_cols)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=scaling_cols)\n",
    "\n",
    "    train_scaled.shape, test_scaled.shape\n",
    "    \n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40509c9-b9a2-483e-b7de-2a42a47f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = num_data_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7082e6-5b3b-47b5-836e-1fab433a3caa",
   "metadata": {},
   "source": [
    "### Categorical Data: One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fdd30d0-5a85-48d5-8983-2fe166a18648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_encode(train_df, test_df, onehot_cols=None):\n",
    "    \n",
    "    onehot_cols = ['gender','car','reality','income_type','edu_type','family_type','house_type','occup_type','work_phone','home_phone','email', 'begin_month', 'CODE']\n",
    "    data = pd.concat([train_df[onehot_cols], test_df[onehot_cols]]) # One-hot encoding using the combination of train and test data\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    # data separation\n",
    "    data = data.reset_index(drop=True)\n",
    "    train_encoded = data.loc[:train_df.shape[0]-1]\n",
    "    test_encoded = data.loc[train_df.shape[0]:]\n",
    "    test_encoded = test_encoded.reset_index(drop=True)\n",
    "    \n",
    "    train_encoded.shape, test_encoded.shape\n",
    "    \n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53b70e7-438a-4bab-bc0e-e58588a1eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = cat_data_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be44a5-9009-426b-85e3-794722ec960b",
   "metadata": {},
   "source": [
    "### Merge scaled numerical data with encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f1fb29-0810-4ac7-b4d9-343a68ac191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded):\n",
    "    \n",
    "    Train = pd.concat([train_scaled,train_encoded],axis=1)\n",
    "    Train = pd.concat([Train,train_df['credit']],axis=1)\n",
    "\n",
    "    Test = pd.concat([test_scaled,test_encoded],axis=1)\n",
    "\n",
    "    Train.shape, Test.shape\n",
    "    \n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e80a91d-a145-46f8-810d-3c027739f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570651c1-6d02-483e-952c-90fabd5a5f7a",
   "metadata": {},
   "source": [
    "## Split Training and Validation set#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4783507-8f94-4764-b221-a80c55f126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Train.drop(['credit'], axis=1)\n",
    "y_data = Train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e24cde9-08ec-48d9-ad54-6e50410f7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00366b1b-d2ac-4475-8d9c-d8bfbbfec8c3",
   "metadata": {},
   "source": [
    "## Train with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6587a936-ed74-4168-82af-cd911c2298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "414114a2-4ba9-49d7-a094-cf74926e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trn, tst, cv = 5):\n",
    "    \n",
    "    tst_preds = []\n",
    "    vld_preds = []\n",
    "    feats_importance = np.zeros(tst.shape[1])    \n",
    "    for n, (trn_idx, vld_idx) in enumerate(StratifiedKFold(cv).split(trn.drop('credit', axis = 1).values, trn['credit'].values)):\n",
    "        print(f\"{n+1}/{cv}th fold..........\")        \n",
    "        X_trn = trn.loc[trn_idx, :].drop('credit', axis = 1)\n",
    "        X_vld = trn.loc[vld_idx, :].drop('credit', axis = 1)\n",
    "        y_trn = trn.loc[trn_idx, 'credit'].values\n",
    "        y_vld = trn.loc[vld_idx, 'credit'].values\n",
    "        \n",
    "        model.fit(\n",
    "            X_trn, y_trn,\n",
    "            eval_set = [(X_trn, y_trn), (X_vld, y_vld)],\n",
    "            verbose = 500, early_stopping_rounds = 30\n",
    "        )    \n",
    "        vld_preds.append(log_loss(y_vld, model.predict_proba(X_vld)))        \n",
    "        \n",
    "        tst_pred = model.predict_proba(tst)\n",
    "        tst_preds.append(tst_pred)\n",
    "        feats_importance += model.feature_importances_                        \n",
    "        \n",
    "    feats_importance = feats_importance / cv\n",
    "    feats_importance = pd.Series(data = feats_importance, index = tst.columns)\n",
    "\n",
    "    print('mlogloss: ', np.mean(vld_preds))\n",
    "    return tst_preds, feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e92776-cb6f-4e8e-9538-2f8eebfa5f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.505877\tvalid_1's multi_logloss: 0.707524\n",
      "2/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506251\tvalid_1's multi_logloss: 0.694409\n",
      "3/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504711\tvalid_1's multi_logloss: 0.715838\n",
      "4/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506196\tvalid_1's multi_logloss: 0.696062\n",
      "5/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.507217\tvalid_1's multi_logloss: 0.698763\n",
      "6/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.5043\tvalid_1's multi_logloss: 0.707221\n",
      "7/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.506672\tvalid_1's multi_logloss: 0.704681\n",
      "8/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504059\tvalid_1's multi_logloss: 0.717582\n",
      "9/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.504313\tvalid_1's multi_logloss: 0.713331\n",
      "10/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.505444\tvalid_1's multi_logloss: 0.708977\n",
      "mlogloss:  0.7019213549067368\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**lgbm_params), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda7ef96-6d16-4fa3-886d-506608cdd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_total                               7307.5\n",
       "family_size                                1424.5\n",
       "days_unemployed                           12781.0\n",
       "income_unemployed                         14395.8\n",
       "Age                                        8089.8\n",
       "                                           ...   \n",
       "CODE_M998790000.0Commercial associate         0.0\n",
       "CODE_M9990292500.0Commercial associate        0.0\n",
       "CODE_M9991157500.0Working                     0.0\n",
       "CODE_M9993180000.0Working                     0.0\n",
       "CODE_M9996135000.0Working                     0.0\n",
       "Length: 9699, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_im_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec158ef-669e-4409-acd2-d97dc848180f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3f66bc-3ddf-45b4-96f2-f8d09a980287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'verbose': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
    "    }\n",
    "    model = LGBMClassifier(**param)\n",
    "    lgb_model = model.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=0, early_stopping_rounds=25)\n",
    "\n",
    "    score = cross_val_score(model, x_data, y_data, cv=5, scoring=\"neg_log_loss\")\n",
    "    log_loss = score.mean()\n",
    "\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b803ff9-9608-48e5-a9ad-b6335022c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 16:54:54,707]\u001b[0m A new study created in memory with name: no-name-ad4c123f-3494-4379-a9e1-21cf27e42024\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:56:05,237]\u001b[0m Trial 0 finished with value: -0.875077307414122 and parameters: {'max_depth': 9, 'learning_rate': 2.8747873517678205e-05, 'n_estimators': 1492, 'min_child_samples': 29, 'subsample': 0.7103652353059032}. Best is trial 0 with value: -0.875077307414122.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:57:05,603]\u001b[0m Trial 1 finished with value: -0.882528433586099 and parameters: {'max_depth': 8, 'learning_rate': 1.355913866357637e-07, 'n_estimators': 721, 'min_child_samples': 97, 'subsample': 0.49870118149829573}. Best is trial 0 with value: -0.875077307414122.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:58:41,946]\u001b[0m Trial 2 finished with value: -0.8821441386010406 and parameters: {'max_depth': 7, 'learning_rate': 8.923398922742617e-07, 'n_estimators': 2501, 'min_child_samples': 64, 'subsample': 0.8532101590237792}. Best is trial 0 with value: -0.875077307414122.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:00:15,489]\u001b[0m Trial 3 finished with value: -0.8819236683822952 and parameters: {'max_depth': 6, 'learning_rate': 1.2831304117193812e-06, 'n_estimators': 2760, 'min_child_samples': 55, 'subsample': 0.6323634271094664}. Best is trial 0 with value: -0.875077307414122.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:01:31,549]\u001b[0m Trial 4 finished with value: -0.8652720438530214 and parameters: {'max_depth': 14, 'learning_rate': 8.816628926921939e-05, 'n_estimators': 1249, 'min_child_samples': 89, 'subsample': 0.7080878955495533}. Best is trial 4 with value: -0.8652720438530214.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:03:00,018]\u001b[0m Trial 5 finished with value: -0.8213953912962593 and parameters: {'max_depth': 7, 'learning_rate': 0.0003035444851596327, 'n_estimators': 2397, 'min_child_samples': 34, 'subsample': 0.6749591816552079}. Best is trial 5 with value: -0.8213953912962593.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:04:31,743]\u001b[0m Trial 6 finished with value: -0.8815071562786038 and parameters: {'max_depth': 10, 'learning_rate': 2.243887843237678e-06, 'n_estimators': 2457, 'min_child_samples': 18, 'subsample': 0.42756353138342845}. Best is trial 5 with value: -0.8213953912962593.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:05:16,347]\u001b[0m Trial 7 finished with value: -0.8806359785802369 and parameters: {'max_depth': 4, 'learning_rate': 4.137199330758418e-05, 'n_estimators': 274, 'min_child_samples': 45, 'subsample': 0.7340183906829687}. Best is trial 5 with value: -0.8213953912962593.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:06:42,346]\u001b[0m Trial 8 finished with value: -0.7462660148979645 and parameters: {'max_depth': 9, 'learning_rate': 0.004477552374896037, 'n_estimators': 2414, 'min_child_samples': 82, 'subsample': 0.4426919582748543}. Best is trial 8 with value: -0.7462660148979645.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 17:09:17,917]\u001b[0m Trial 9 finished with value: -0.8825331228457646 and parameters: {'max_depth': 15, 'learning_rate': 2.4763144806914182e-08, 'n_estimators': 2695, 'min_child_samples': 6, 'subsample': 0.8753700371069932}. Best is trial 8 with value: -0.7462660148979645.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.7462660148979645\n",
      "Best trial {'max_depth': 9, 'learning_rate': 0.004477552374896037, 'n_estimators': 2414, 'min_child_samples': 82, 'subsample': 0.4426919582748543}\n"
     ]
    }
   ],
   "source": [
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best Score:\",lgbm_study.best_value)\n",
    "print(\"Best trial\",lgbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e68c34b9-7974-4d36-ab92-0f700d3977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameterization\n",
    "\n",
    "p_optuna = {\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.004477552374896037,\n",
    "    'n_estimators': 2414,\n",
    "    'min_child_samples': 82,\n",
    "    'subsample': 0.4426919582748543,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc0b37c-7a06-4608-b925-a85561cad254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.758924\tvalid_1's multi_logloss: 0.785473\n",
      "[1000]\ttraining's multi_logloss: 0.718764\tvalid_1's multi_logloss: 0.770696\n",
      "[1500]\ttraining's multi_logloss: 0.687918\tvalid_1's multi_logloss: 0.759505\n",
      "[2000]\ttraining's multi_logloss: 0.663583\tvalid_1's multi_logloss: 0.750955\n",
      "2/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.757985\tvalid_1's multi_logloss: 0.783876\n",
      "[1000]\ttraining's multi_logloss: 0.719207\tvalid_1's multi_logloss: 0.764869\n",
      "[1500]\ttraining's multi_logloss: 0.689358\tvalid_1's multi_logloss: 0.750423\n",
      "[2000]\ttraining's multi_logloss: 0.664338\tvalid_1's multi_logloss: 0.741547\n",
      "3/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.756735\tvalid_1's multi_logloss: 0.79266\n",
      "[1000]\ttraining's multi_logloss: 0.716267\tvalid_1's multi_logloss: 0.777487\n",
      "[1500]\ttraining's multi_logloss: 0.685813\tvalid_1's multi_logloss: 0.766828\n",
      "[2000]\ttraining's multi_logloss: 0.659914\tvalid_1's multi_logloss: 0.758565\n",
      "4/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.759499\tvalid_1's multi_logloss: 0.785622\n",
      "[1000]\ttraining's multi_logloss: 0.719334\tvalid_1's multi_logloss: 0.76546\n",
      "[1500]\ttraining's multi_logloss: 0.688415\tvalid_1's multi_logloss: 0.75076\n",
      "[2000]\ttraining's multi_logloss: 0.663166\tvalid_1's multi_logloss: 0.741035\n",
      "5/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.759031\tvalid_1's multi_logloss: 0.790073\n",
      "[1000]\ttraining's multi_logloss: 0.719068\tvalid_1's multi_logloss: 0.770865\n",
      "[1500]\ttraining's multi_logloss: 0.688659\tvalid_1's multi_logloss: 0.75705\n",
      "[2000]\ttraining's multi_logloss: 0.664091\tvalid_1's multi_logloss: 0.74731\n",
      "6/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.757782\tvalid_1's multi_logloss: 0.787349\n",
      "[1000]\ttraining's multi_logloss: 0.717846\tvalid_1's multi_logloss: 0.768318\n",
      "[1500]\ttraining's multi_logloss: 0.687018\tvalid_1's multi_logloss: 0.75588\n",
      "[2000]\ttraining's multi_logloss: 0.660238\tvalid_1's multi_logloss: 0.745639\n",
      "7/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.757995\tvalid_1's multi_logloss: 0.79063\n",
      "[1000]\ttraining's multi_logloss: 0.717295\tvalid_1's multi_logloss: 0.77346\n",
      "[1500]\ttraining's multi_logloss: 0.687619\tvalid_1's multi_logloss: 0.761157\n",
      "[2000]\ttraining's multi_logloss: 0.661947\tvalid_1's multi_logloss: 0.752733\n",
      "8/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.759061\tvalid_1's multi_logloss: 0.785708\n",
      "[1000]\ttraining's multi_logloss: 0.718723\tvalid_1's multi_logloss: 0.770452\n",
      "[1500]\ttraining's multi_logloss: 0.686936\tvalid_1's multi_logloss: 0.759048\n",
      "[2000]\ttraining's multi_logloss: 0.661493\tvalid_1's multi_logloss: 0.75168\n",
      "9/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.75952\tvalid_1's multi_logloss: 0.786679\n",
      "[1000]\ttraining's multi_logloss: 0.720051\tvalid_1's multi_logloss: 0.76903\n",
      "[1500]\ttraining's multi_logloss: 0.688808\tvalid_1's multi_logloss: 0.757272\n",
      "[2000]\ttraining's multi_logloss: 0.661848\tvalid_1's multi_logloss: 0.749055\n",
      "10/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.756901\tvalid_1's multi_logloss: 0.793127\n",
      "[1000]\ttraining's multi_logloss: 0.716924\tvalid_1's multi_logloss: 0.776224\n",
      "[1500]\ttraining's multi_logloss: 0.687742\tvalid_1's multi_logloss: 0.76322\n",
      "[2000]\ttraining's multi_logloss: 0.662995\tvalid_1's multi_logloss: 0.753869\n",
      "mlogloss:  0.7427299971769363\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**p_optuna), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe16e0-5abd-4777-8a23-c0b3b9e34f64",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2a657-6c79-46ed-94ab-34fd468093c9",
   "metadata": {},
   "source": [
    "**Manual: 0.7019** / Tuned: 0 7913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890cfc-6c01-4b42-a03f-f2b8b5a65678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
