{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb0d1f7-fdb4-48b6-9fcd-f7d9f579c99a",
   "metadata": {},
   "source": [
    "# LGBM - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728b35-a6dd-4327-9715-8bfa8f5c5996",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83ce26c-3dfd-40e2-be26-4c8779413f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996df80-8d54-4e82-bc40-61b2199a8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>days_birth</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occup_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No job</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-13899202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-11380247500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M-19087450000.0Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F-15088202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F-15037157500.0State servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  child_num  income_total  \\\n",
       "0           0      F   N       N          0      202500.0   \n",
       "1           1      F   N       Y          1      247500.0   \n",
       "2           2      M   Y       Y          0      450000.0   \n",
       "3           3      F   N       Y          0      202500.0   \n",
       "4           4      F   Y       Y          0      157500.0   \n",
       "\n",
       "            income_type                       edu_type     family_type  \\\n",
       "0  Commercial associate               Higher education         Married   \n",
       "1  Commercial associate  Secondary / secondary special  Civil marriage   \n",
       "2               Working               Higher education         Married   \n",
       "3  Commercial associate  Secondary / secondary special         Married   \n",
       "4         State servant               Higher education         Married   \n",
       "\n",
       "            house_type  days_birth  days_employed  work_phone  home_phone  \\\n",
       "0  Municipal apartment       13899           4709           0           0   \n",
       "1    House / apartment       11380           1540           0           0   \n",
       "2    House / apartment       19087           4434           0           1   \n",
       "3    House / apartment       15088           2092           0           1   \n",
       "4    House / apartment       15037           2105           0           0   \n",
       "\n",
       "   email   occup_type  family_size  begin_month  credit  \\\n",
       "0      0       No job          2.0            6     1.0   \n",
       "1      1     Laborers          3.0            5     1.0   \n",
       "2      0     Managers          2.0           22     2.0   \n",
       "3      0  Sales staff          2.0           37     0.0   \n",
       "4      0     Managers          2.0           26     2.0   \n",
       "\n",
       "                                  CODE  \n",
       "0  F-13899202500.0Commercial associate  \n",
       "1  F-11380247500.0Commercial associate  \n",
       "2               M-19087450000.0Working  \n",
       "3  F-15088202500.0Commercial associate  \n",
       "4         F-15037157500.0State servant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"../data/cleaned_train.csv\")\n",
    "test_df=pd.read_csv(\"../data/cleaned_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153ab41-bd52-4f6b-b942-bddacc461c0b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb9b5-1f99-43e7-95da-b1aa2e3f4984",
   "metadata": {},
   "source": [
    "### Numerical Data: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ecd7f4-7d09-4121-9beb-6a6113cc3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data_scale(train_df, test_df, scaling_cols=None):\n",
    "    \n",
    "    scaling_cols = ['child_num','income_total','days_birth','days_employed','family_size','begin_month']\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "    train_scaled = std_scaler.transform(train_df[scaling_cols])\n",
    "    test_scaled = std_scaler.transform(test_df[scaling_cols]) # Apply to the test set using the scaler that was fitted with train data!!\n",
    "\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=scaling_cols)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=scaling_cols)\n",
    "\n",
    "    train_scaled.shape, test_scaled.shape\n",
    "    \n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40509c9-b9a2-483e-b7de-2a42a47f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = num_data_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7082e6-5b3b-47b5-836e-1fab433a3caa",
   "metadata": {},
   "source": [
    "### Categorical Data: One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdd30d0-5a85-48d5-8983-2fe166a18648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_encode(train_df, test_df, onehot_cols=None):\n",
    "    \n",
    "    onehot_cols = ['gender','car','reality','income_type','edu_type','family_type','house_type','occup_type','work_phone','home_phone','email', 'CODE']\n",
    "    data = pd.concat([train_df[onehot_cols], test_df[onehot_cols]]) # One-hot encoding using the combination of train and test data\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    # data separation\n",
    "    data = data.reset_index(drop=True)\n",
    "    train_encoded = data.loc[:train_df.shape[0]-1]\n",
    "    test_encoded = data.loc[train_df.shape[0]:]\n",
    "    test_encoded = test_encoded.reset_index(drop=True)\n",
    "    \n",
    "    train_encoded.shape, test_encoded.shape\n",
    "    \n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53b70e7-438a-4bab-bc0e-e58588a1eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = cat_data_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be44a5-9009-426b-85e3-794722ec960b",
   "metadata": {},
   "source": [
    "### Merge scaled numerical data with encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f1fb29-0810-4ac7-b4d9-343a68ac191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded):\n",
    "    \n",
    "    Train = pd.concat([train_scaled,train_encoded],axis=1)\n",
    "    Train = pd.concat([Train,train_df['credit']],axis=1)\n",
    "\n",
    "    Test = pd.concat([test_scaled,test_encoded],axis=1)\n",
    "\n",
    "    Train.shape, Test.shape\n",
    "    \n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e80a91d-a145-46f8-810d-3c027739f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570651c1-6d02-483e-952c-90fabd5a5f7a",
   "metadata": {},
   "source": [
    "## Split Training and Validation set#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4783507-8f94-4764-b221-a80c55f126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Train.drop(['credit'], axis=1)\n",
    "y_data = Train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e24cde9-08ec-48d9-ad54-6e50410f7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00366b1b-d2ac-4475-8d9c-d8bfbbfec8c3",
   "metadata": {},
   "source": [
    "## Train with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6587a936-ed74-4168-82af-cd911c2298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414114a2-4ba9-49d7-a094-cf74926e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trn, tst, cv = 5):\n",
    "    \n",
    "    tst_preds = []\n",
    "    vld_preds = []\n",
    "    feats_importance = np.zeros(tst.shape[1])    \n",
    "    for n, (trn_idx, vld_idx) in enumerate(StratifiedKFold(cv).split(trn.drop('credit', axis = 1).values, trn['credit'].values)):\n",
    "        print(f\"{n+1}/{cv}th fold..........\")        \n",
    "        X_trn = trn.loc[trn_idx, :].drop('credit', axis = 1)\n",
    "        X_vld = trn.loc[vld_idx, :].drop('credit', axis = 1)\n",
    "        y_trn = trn.loc[trn_idx, 'credit'].values\n",
    "        y_vld = trn.loc[vld_idx, 'credit'].values\n",
    "        \n",
    "        model.fit(\n",
    "            X_trn, y_trn,\n",
    "            eval_set = [(X_trn, y_trn), (X_vld, y_vld)],\n",
    "            verbose = 500, early_stopping_rounds = 30\n",
    "        )    \n",
    "        vld_preds.append(log_loss(y_vld, model.predict_proba(X_vld)))        \n",
    "        \n",
    "        tst_pred = model.predict_proba(tst)\n",
    "        tst_preds.append(tst_pred)\n",
    "        feats_importance += model.feature_importances_                        \n",
    "        \n",
    "    feats_importance = feats_importance / cv\n",
    "    feats_importance = pd.Series(data = feats_importance, index = tst.columns)\n",
    "\n",
    "    print('mlogloss: ', np.mean(vld_preds))\n",
    "    return tst_preds, feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e92776-cb6f-4e8e-9538-2f8eebfa5f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560762\tvalid_1's multi_logloss: 0.759223\n",
      "2/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.56255\tvalid_1's multi_logloss: 0.739597\n",
      "3/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560735\tvalid_1's multi_logloss: 0.757353\n",
      "4/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.56094\tvalid_1's multi_logloss: 0.746335\n",
      "5/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560028\tvalid_1's multi_logloss: 0.752481\n",
      "6/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.561561\tvalid_1's multi_logloss: 0.741933\n",
      "7/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.559789\tvalid_1's multi_logloss: 0.759988\n",
      "8/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "9/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.55843\tvalid_1's multi_logloss: 0.75501\n",
      "10/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.558702\tvalid_1's multi_logloss: 0.76764\n",
      "mlogloss:  0.7525332502904052\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**lgbm_params), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fda7ef96-6d16-4fa3-886d-506608cdd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "child_num                                   1871.1\n",
       "income_total                               15312.1\n",
       "days_birth                                 23002.4\n",
       "days_employed                              19902.3\n",
       "family_size                                 2174.0\n",
       "                                            ...   \n",
       "CODE_M-998790000.0Commercial associate         0.0\n",
       "CODE_M-9990292500.0Commercial associate        0.0\n",
       "CODE_M-9991157500.0Working                     0.0\n",
       "CODE_M-9993180000.0Working                     0.0\n",
       "CODE_M-9996135000.0Working                     0.0\n",
       "Length: 9690, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_im_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec158ef-669e-4409-acd2-d97dc848180f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3f66bc-3ddf-45b4-96f2-f8d09a980287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'verbose': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
    "    }\n",
    "    model = LGBMClassifier(**param)\n",
    "    lgb_model = model.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=0, early_stopping_rounds=25)\n",
    "\n",
    "    score = cross_val_score(model, x_data, y_data, cv=5, scoring=\"neg_log_loss\")\n",
    "    log_loss = score.mean()\n",
    "\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b803ff9-9608-48e5-a9ad-b6335022c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 16:20:31,879]\u001b[0m A new study created in memory with name: no-name-04afe976-6ea7-48e8-ab84-49162623e491\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:21:13,574]\u001b[0m Trial 0 finished with value: -0.8178811185238409 and parameters: {'max_depth': 14, 'learning_rate': 0.0036694835440513416, 'n_estimators': 278, 'min_child_samples': 75, 'subsample': 0.731834254241718}. Best is trial 0 with value: -0.8178811185238409.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:22:02,039]\u001b[0m Trial 1 finished with value: -0.8185361053014258 and parameters: {'max_depth': 3, 'learning_rate': 0.0008467094608685681, 'n_estimators': 1913, 'min_child_samples': 49, 'subsample': 0.7249337160565229}. Best is trial 0 with value: -0.8178811185238409.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:23:30,160]\u001b[0m Trial 2 finished with value: -0.7954731150805342 and parameters: {'max_depth': 11, 'learning_rate': 0.0012519922459335428, 'n_estimators': 2829, 'min_child_samples': 92, 'subsample': 0.4178388725657859}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:24:35,458]\u001b[0m Trial 3 finished with value: -0.8870887227478328 and parameters: {'max_depth': 12, 'learning_rate': 1.638633928774733e-07, 'n_estimators': 1333, 'min_child_samples': 41, 'subsample': 0.8539069576528204}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:25:37,696]\u001b[0m Trial 4 finished with value: -0.8274671822158522 and parameters: {'max_depth': 9, 'learning_rate': 0.0006735588098547652, 'n_estimators': 1054, 'min_child_samples': 56, 'subsample': 0.8138145552464755}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:26:57,706]\u001b[0m Trial 5 finished with value: -0.8833449181466445 and parameters: {'max_depth': 10, 'learning_rate': 1.1497379853571229e-05, 'n_estimators': 1886, 'min_child_samples': 43, 'subsample': 0.922032875955368}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:28:29,023]\u001b[0m Trial 6 finished with value: -0.8766418970611722 and parameters: {'max_depth': 12, 'learning_rate': 3.258141975069771e-05, 'n_estimators': 1962, 'min_child_samples': 7, 'subsample': 0.7792113041971362}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:30:00,793]\u001b[0m Trial 7 finished with value: -0.8810196807557562 and parameters: {'max_depth': 9, 'learning_rate': 1.294618237931433e-05, 'n_estimators': 2780, 'min_child_samples': 59, 'subsample': 0.4430006794196981}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:31:10,164]\u001b[0m Trial 8 finished with value: -0.8856000296057118 and parameters: {'max_depth': 7, 'learning_rate': 4.657126697858569e-06, 'n_estimators': 1889, 'min_child_samples': 57, 'subsample': 0.9160188607994989}. Best is trial 2 with value: -0.7954731150805342.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:32:15,986]\u001b[0m Trial 9 finished with value: -0.7910297091060929 and parameters: {'max_depth': 7, 'learning_rate': 0.005531892472467897, 'n_estimators': 1534, 'min_child_samples': 5, 'subsample': 0.549757753424006}. Best is trial 9 with value: -0.7910297091060929.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.7910297091060929\n",
      "Best trial {'max_depth': 7, 'learning_rate': 0.005531892472467897, 'n_estimators': 1534, 'min_child_samples': 5, 'subsample': 0.549757753424006}\n"
     ]
    }
   ],
   "source": [
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best Score:\",lgbm_study.best_value)\n",
    "print(\"Best trial\",lgbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14680514-42f3-4081-acc7-ff9aa449f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameterization\n",
    "\n",
    "p_optuna = {\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.005531892472467897,\n",
    "    'n_estimators': 1534,\n",
    "    'min_child_samples': 5,\n",
    "    'subsample': 0.549757753424006,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83c439a-4f8c-4da3-88e0-781d542c9130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.779722\tvalid_1's multi_logloss: 0.805344\n",
      "[1000]\ttraining's multi_logloss: 0.762134\tvalid_1's multi_logloss: 0.797011\n",
      "[1500]\ttraining's multi_logloss: 0.750835\tvalid_1's multi_logloss: 0.792265\n",
      "2/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.779436\tvalid_1's multi_logloss: 0.80382\n",
      "[1000]\ttraining's multi_logloss: 0.762123\tvalid_1's multi_logloss: 0.794357\n",
      "[1500]\ttraining's multi_logloss: 0.751329\tvalid_1's multi_logloss: 0.789113\n",
      "3/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.780235\tvalid_1's multi_logloss: 0.803762\n",
      "[1000]\ttraining's multi_logloss: 0.762929\tvalid_1's multi_logloss: 0.79338\n",
      "[1500]\ttraining's multi_logloss: 0.751803\tvalid_1's multi_logloss: 0.788057\n",
      "4/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.779935\tvalid_1's multi_logloss: 0.802172\n",
      "[1000]\ttraining's multi_logloss: 0.762698\tvalid_1's multi_logloss: 0.793328\n",
      "[1500]\ttraining's multi_logloss: 0.75175\tvalid_1's multi_logloss: 0.787295\n",
      "5/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.780184\tvalid_1's multi_logloss: 0.807715\n",
      "[1000]\ttraining's multi_logloss: 0.76223\tvalid_1's multi_logloss: 0.797634\n",
      "[1500]\ttraining's multi_logloss: 0.751357\tvalid_1's multi_logloss: 0.792931\n",
      "6/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.781048\tvalid_1's multi_logloss: 0.804876\n",
      "[1000]\ttraining's multi_logloss: 0.763436\tvalid_1's multi_logloss: 0.794707\n",
      "[1500]\ttraining's multi_logloss: 0.752437\tvalid_1's multi_logloss: 0.789256\n",
      "7/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.779819\tvalid_1's multi_logloss: 0.809635\n",
      "[1000]\ttraining's multi_logloss: 0.762026\tvalid_1's multi_logloss: 0.801194\n",
      "[1500]\ttraining's multi_logloss: 0.750478\tvalid_1's multi_logloss: 0.796957\n",
      "8/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.779586\tvalid_1's multi_logloss: 0.805479\n",
      "[1000]\ttraining's multi_logloss: 0.761881\tvalid_1's multi_logloss: 0.797717\n",
      "[1500]\ttraining's multi_logloss: 0.75056\tvalid_1's multi_logloss: 0.794112\n",
      "9/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.780755\tvalid_1's multi_logloss: 0.799664\n",
      "[1000]\ttraining's multi_logloss: 0.763123\tvalid_1's multi_logloss: 0.790607\n",
      "[1500]\ttraining's multi_logloss: 0.751636\tvalid_1's multi_logloss: 0.785755\n",
      "10/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.777755\tvalid_1's multi_logloss: 0.813392\n",
      "[1000]\ttraining's multi_logloss: 0.760293\tvalid_1's multi_logloss: 0.804837\n",
      "[1500]\ttraining's multi_logloss: 0.749331\tvalid_1's multi_logloss: 0.800394\n",
      "mlogloss:  0.7913346780855954\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**p_optuna), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe16e0-5abd-4777-8a23-c0b3b9e34f64",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2a657-6c79-46ed-94ab-34fd468093c9",
   "metadata": {},
   "source": [
    "**Manual: 0.7525** / Tuned: 0.7913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890cfc-6c01-4b42-a03f-f2b8b5a65678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
