{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb0d1f7-fdb4-48b6-9fcd-f7d9f579c99a",
   "metadata": {},
   "source": [
    "# LGBM - Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728b35-a6dd-4327-9715-8bfa8f5c5996",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f83ce26c-3dfd-40e2-be26-4c8779413f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996df80-8d54-4e82-bc40-61b2199a8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>days_birth</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occup_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No job</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-13899202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-11380247500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M-19087450000.0Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F-15088202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F-15037157500.0State servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  child_num  income_total  \\\n",
       "0           0      F   N       N          0      202500.0   \n",
       "1           1      F   N       Y          1      247500.0   \n",
       "2           2      M   Y       Y          0      450000.0   \n",
       "3           3      F   N       Y          0      202500.0   \n",
       "4           4      F   Y       Y          0      157500.0   \n",
       "\n",
       "            income_type                       edu_type     family_type  \\\n",
       "0  Commercial associate               Higher education         Married   \n",
       "1  Commercial associate  Secondary / secondary special  Civil marriage   \n",
       "2               Working               Higher education         Married   \n",
       "3  Commercial associate  Secondary / secondary special         Married   \n",
       "4         State servant               Higher education         Married   \n",
       "\n",
       "            house_type  days_birth  days_employed  work_phone  home_phone  \\\n",
       "0  Municipal apartment       13899           4709           0           0   \n",
       "1    House / apartment       11380           1540           0           0   \n",
       "2    House / apartment       19087           4434           0           1   \n",
       "3    House / apartment       15088           2092           0           1   \n",
       "4    House / apartment       15037           2105           0           0   \n",
       "\n",
       "   email   occup_type  family_size  begin_month  credit  \\\n",
       "0      0       No job          2.0            6     1.0   \n",
       "1      1     Laborers          3.0            5     1.0   \n",
       "2      0     Managers          2.0           22     2.0   \n",
       "3      0  Sales staff          2.0           37     0.0   \n",
       "4      0     Managers          2.0           26     2.0   \n",
       "\n",
       "                                  CODE  \n",
       "0  F-13899202500.0Commercial associate  \n",
       "1  F-11380247500.0Commercial associate  \n",
       "2               M-19087450000.0Working  \n",
       "3  F-15088202500.0Commercial associate  \n",
       "4         F-15037157500.0State servant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"../data/cleaned_train.csv\")\n",
    "test_df=pd.read_csv(\"../data/cleaned_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153ab41-bd52-4f6b-b942-bddacc461c0b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb9b5-1f99-43e7-95da-b1aa2e3f4984",
   "metadata": {},
   "source": [
    "### Numerical Data: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ecd7f4-7d09-4121-9beb-6a6113cc3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data_scale(train_df, test_df, scaling_cols=None):\n",
    "    \n",
    "    scaling_cols = ['child_num','income_total','days_birth','days_employed','family_size','begin_month']\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "    train_scaled = std_scaler.transform(train_df[scaling_cols])\n",
    "    test_scaled = std_scaler.transform(test_df[scaling_cols]) # Apply to the test set using the scaler that was fitted with train data!!\n",
    "\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=scaling_cols)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=scaling_cols)\n",
    "\n",
    "    train_scaled.shape, test_scaled.shape\n",
    "    \n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40509c9-b9a2-483e-b7de-2a42a47f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = num_data_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7082e6-5b3b-47b5-836e-1fab433a3caa",
   "metadata": {},
   "source": [
    "### Categorical Data: One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdd30d0-5a85-48d5-8983-2fe166a18648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_encode(train_df, test_df, onehot_cols=None):\n",
    "    \n",
    "    onehot_cols = ['gender','car','reality','income_type','edu_type','family_type','house_type','occup_type','work_phone','home_phone','email']\n",
    "    data = pd.concat([train_df[onehot_cols], test_df[onehot_cols]]) # One-hot encoding using the combination of train and test data\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    # data separation\n",
    "    data = data.reset_index(drop=True)\n",
    "    train_encoded = data.loc[:train_df.shape[0]-1]\n",
    "    test_encoded = data.loc[train_df.shape[0]:]\n",
    "    test_encoded = test_encoded.reset_index(drop=True)\n",
    "    \n",
    "    train_encoded.shape, test_encoded.shape\n",
    "    \n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c53b70e7-438a-4bab-bc0e-e58588a1eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = cat_data_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be44a5-9009-426b-85e3-794722ec960b",
   "metadata": {},
   "source": [
    "### Merge scaled numerical data with encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f1fb29-0810-4ac7-b4d9-343a68ac191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded):\n",
    "    \n",
    "    Train = pd.concat([train_scaled,train_encoded],axis=1)\n",
    "    Train = pd.concat([Train,train_df['credit']],axis=1)\n",
    "\n",
    "    Test = pd.concat([test_scaled,test_encoded],axis=1)\n",
    "\n",
    "    Train.shape, Test.shape\n",
    "    \n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e80a91d-a145-46f8-810d-3c027739f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570651c1-6d02-483e-952c-90fabd5a5f7a",
   "metadata": {},
   "source": [
    "## Split Training and Validation set#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4783507-8f94-4764-b221-a80c55f126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Train.drop(['credit'], axis=1)\n",
    "y_data = Train['credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e24cde9-08ec-48d9-ad54-6e50410f7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00366b1b-d2ac-4475-8d9c-d8bfbbfec8c3",
   "metadata": {},
   "source": [
    "## Train with LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6587a936-ed74-4168-82af-cd911c2298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "414114a2-4ba9-49d7-a094-cf74926e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trn, tst, cv = 5):\n",
    "    \n",
    "    tst_preds = []\n",
    "    vld_preds = []\n",
    "    feats_importance = np.zeros(tst.shape[1])    \n",
    "    for n, (trn_idx, vld_idx) in enumerate(StratifiedKFold(cv).split(trn.drop('credit', axis = 1).values, trn['credit'].values)):\n",
    "        print(f\"{n+1}/{cv}th fold..........\")        \n",
    "        X_trn = trn.loc[trn_idx, :].drop('credit', axis = 1)\n",
    "        X_vld = trn.loc[vld_idx, :].drop('credit', axis = 1)\n",
    "        y_trn = trn.loc[trn_idx, 'credit'].values\n",
    "        y_vld = trn.loc[vld_idx, 'credit'].values\n",
    "        \n",
    "        model.fit(\n",
    "            X_trn, y_trn,\n",
    "            eval_set = [(X_trn, y_trn), (X_vld, y_vld)],\n",
    "            verbose = 500, early_stopping_rounds = 30\n",
    "        )    \n",
    "        vld_preds.append(log_loss(y_vld, model.predict_proba(X_vld)))        \n",
    "        \n",
    "        tst_pred = model.predict_proba(tst)\n",
    "        tst_preds.append(tst_pred)\n",
    "        feats_importance += model.feature_importances_                        \n",
    "        \n",
    "    feats_importance = feats_importance / cv\n",
    "    feats_importance = pd.Series(data = feats_importance, index = tst.columns)\n",
    "\n",
    "    print('mlogloss: ', np.mean(vld_preds))\n",
    "    return tst_preds, feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76e92776-cb6f-4e8e-9538-2f8eebfa5f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560762\tvalid_1's multi_logloss: 0.759223\n",
      "2/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.56255\tvalid_1's multi_logloss: 0.739597\n",
      "3/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560735\tvalid_1's multi_logloss: 0.757353\n",
      "4/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.56094\tvalid_1's multi_logloss: 0.746335\n",
      "5/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.560028\tvalid_1's multi_logloss: 0.752481\n",
      "6/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.561561\tvalid_1's multi_logloss: 0.741933\n",
      "7/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.559789\tvalid_1's multi_logloss: 0.759988\n",
      "8/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "9/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.55843\tvalid_1's multi_logloss: 0.75501\n",
      "10/10th fold..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[500]\ttraining's multi_logloss: 0.558702\tvalid_1's multi_logloss: 0.76764\n",
      "mlogloss:  0.7525332502904052\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**lgbm_params), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fda7ef96-6d16-4fa3-886d-506608cdd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "child_num                                  1313.9\n",
       "income_total                              10721.4\n",
       "days_birth                                13508.0\n",
       "days_employed                             11383.5\n",
       "family_size                                1300.3\n",
       "begin_month                                7123.1\n",
       "work_phone                                  860.8\n",
       "home_phone                                  942.7\n",
       "email                                       548.1\n",
       "gender_F                                    804.7\n",
       "gender_M                                     48.6\n",
       "car_N                                       685.6\n",
       "car_Y                                        75.2\n",
       "reality_N                                   924.9\n",
       "reality_Y                                   121.4\n",
       "income_type_Commercial associate            715.6\n",
       "income_type_Pensioner                        10.2\n",
       "income_type_State servant                   418.1\n",
       "income_type_Student                           0.0\n",
       "income_type_Working                         646.2\n",
       "edu_type_Academic degree                      0.0\n",
       "edu_type_Higher education                   997.3\n",
       "edu_type_Incomplete higher                  313.8\n",
       "edu_type_Lower secondary                      8.1\n",
       "edu_type_Secondary / secondary special      547.4\n",
       "family_type_Civil marriage                  564.2\n",
       "family_type_Married                         718.4\n",
       "family_type_Separated                       365.1\n",
       "family_type_Single / not married            503.7\n",
       "family_type_Widow                           248.3\n",
       "house_type_Co-op apartment                   65.0\n",
       "house_type_House / apartment                545.6\n",
       "house_type_Municipal apartment              491.9\n",
       "house_type_Office apartment                 136.8\n",
       "house_type_Rented apartment                 512.8\n",
       "house_type_With parents                     308.4\n",
       "occup_type_Accountants                      441.1\n",
       "occup_type_Cleaning staff                    84.7\n",
       "occup_type_Cooking staff                    293.8\n",
       "occup_type_Core staff                       644.6\n",
       "occup_type_Drivers                          353.5\n",
       "occup_type_HR staff                         297.3\n",
       "occup_type_High skill tech staff            605.1\n",
       "occup_type_IT staff                          86.6\n",
       "occup_type_Laborers                         455.9\n",
       "occup_type_Low-skill Laborers                49.7\n",
       "occup_type_Managers                         476.8\n",
       "occup_type_Medicine staff                   421.3\n",
       "occup_type_No job                           925.1\n",
       "occup_type_Private service staff            131.0\n",
       "occup_type_Realty agents                    132.1\n",
       "occup_type_Sales staff                      570.0\n",
       "occup_type_Secretaries                      100.7\n",
       "occup_type_Security staff                   176.0\n",
       "occup_type_Waiters/barmen staff             342.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_im_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec158ef-669e-4409-acd2-d97dc848180f",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a3f66bc-3ddf-45b4-96f2-f8d09a980287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler = TPESampler(seed=10)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        'verbose': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth',3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-8, 1e-2),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.4, 1),\n",
    "    }\n",
    "    model = LGBMClassifier(**param)\n",
    "    lgb_model = model.fit(train_X, train_y, eval_set=[(val_X, val_y)], verbose=0, early_stopping_rounds=25)\n",
    "\n",
    "    score = cross_val_score(model, x_data, y_data, cv=5, scoring=\"neg_log_loss\")\n",
    "    log_loss = score.mean()\n",
    "\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b803ff9-9608-48e5-a9ad-b6335022c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-11 16:01:47,686]\u001b[0m A new study created in memory with name: no-name-ca6124d2-c931-4250-949a-e38d658acc78\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:02:56,274]\u001b[0m Trial 0 finished with value: -0.8870699766271215 and parameters: {'max_depth': 5, 'learning_rate': 1.2557085970317223e-07, 'n_estimators': 2704, 'min_child_samples': 38, 'subsample': 0.6719026542760719}. Best is trial 0 with value: -0.8870699766271215.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:03:00,973]\u001b[0m Trial 1 finished with value: -0.8871277185531709 and parameters: {'max_depth': 11, 'learning_rate': 2.6176366731794935e-08, 'n_estimators': 125, 'min_child_samples': 21, 'subsample': 0.6641668499374586}. Best is trial 0 with value: -0.8870699766271215.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:03:31,000]\u001b[0m Trial 2 finished with value: -0.8866673833270845 and parameters: {'max_depth': 9, 'learning_rate': 2.7311971246550702e-06, 'n_estimators': 941, 'min_child_samples': 41, 'subsample': 0.4880886703403706}. Best is trial 2 with value: -0.8866673833270845.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:04:42,350]\u001b[0m Trial 3 finished with value: -0.8839897435312771 and parameters: {'max_depth': 13, 'learning_rate': 8.928694023056032e-06, 'n_estimators': 2017, 'min_child_samples': 84, 'subsample': 0.6550492810372811}. Best is trial 3 with value: -0.8839897435312771.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:06:18,130]\u001b[0m Trial 4 finished with value: -0.8781497940349616 and parameters: {'max_depth': 11, 'learning_rate': 2.204132401905564e-05, 'n_estimators': 2443, 'min_child_samples': 36, 'subsample': 0.9989280239625817}. Best is trial 4 with value: -0.8781497940349616.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:07:29,710]\u001b[0m Trial 5 finished with value: -0.8775150925535475 and parameters: {'max_depth': 7, 'learning_rate': 2.7965525893453938e-05, 'n_estimators': 2106, 'min_child_samples': 6, 'subsample': 0.8865939785828931}. Best is trial 5 with value: -0.8775150925535475.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:08:08,637]\u001b[0m Trial 6 finished with value: -0.8868302512105334 and parameters: {'max_depth': 7, 'learning_rate': 1.4838881817254438e-06, 'n_estimators': 1122, 'min_child_samples': 17, 'subsample': 0.45493938476866375}. Best is trial 5 with value: -0.8775150925535475.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:08:26,578]\u001b[0m Trial 7 finished with value: -0.8871173172769004 and parameters: {'max_depth': 3, 'learning_rate': 4.0691311833692264e-08, 'n_estimators': 1612, 'min_child_samples': 61, 'subsample': 0.7832145321007861}. Best is trial 5 with value: -0.8775150925535475.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:10:09,566]\u001b[0m Trial 8 finished with value: -0.824394222962795 and parameters: {'max_depth': 9, 'learning_rate': 0.000276116357251457, 'n_estimators': 2930, 'min_child_samples': 74, 'subsample': 0.5093531702406495}. Best is trial 8 with value: -0.824394222962795.\u001b[0m\n",
      "\u001b[32m[I 2022-12-11 16:10:32,736]\u001b[0m Trial 9 finished with value: -0.802241305364784 and parameters: {'max_depth': 10, 'learning_rate': 0.002666486712509659, 'n_estimators': 713, 'min_child_samples': 12, 'subsample': 0.9469302725441361}. Best is trial 9 with value: -0.802241305364784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.802241305364784\n",
      "Best trial {'max_depth': 10, 'learning_rate': 0.002666486712509659, 'n_estimators': 713, 'min_child_samples': 12, 'subsample': 0.9469302725441361}\n"
     ]
    }
   ],
   "source": [
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best Score:\",lgbm_study.best_value)\n",
    "print(\"Best trial\",lgbm_study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c503c05-120d-419c-9b87-fd2688162713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameterization\n",
    "\n",
    "p_optuna = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.002666486712509659,\n",
    "    'n_estimators': 713,\n",
    "    'min_child_samples': 12,\n",
    "    'subsample': 0.9469302725441361,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3a79f92-34fa-4329-b6b8-d5c17b4f73f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790675\tvalid_1's multi_logloss: 0.807481\n",
      "2/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790997\tvalid_1's multi_logloss: 0.806494\n",
      "3/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790566\tvalid_1's multi_logloss: 0.810234\n",
      "4/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.7915\tvalid_1's multi_logloss: 0.809088\n",
      "5/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790092\tvalid_1's multi_logloss: 0.810416\n",
      "6/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.791351\tvalid_1's multi_logloss: 0.807713\n",
      "7/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790123\tvalid_1's multi_logloss: 0.810538\n",
      "8/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.790622\tvalid_1's multi_logloss: 0.80701\n",
      "9/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.78968\tvalid_1's multi_logloss: 0.806749\n",
      "10/10th fold..........\n",
      "[500]\ttraining's multi_logloss: 0.789093\tvalid_1's multi_logloss: 0.817476\n",
      "mlogloss:  0.8015389815875885\n"
     ]
    }
   ],
   "source": [
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**p_optuna), Train, Test, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe16e0-5abd-4777-8a23-c0b3b9e34f64",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2a657-6c79-46ed-94ab-34fd468093c9",
   "metadata": {},
   "source": [
    "**Manual: 0.7525** / Tuned: 0.8015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890cfc-6c01-4b42-a03f-f2b8b5a65678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
