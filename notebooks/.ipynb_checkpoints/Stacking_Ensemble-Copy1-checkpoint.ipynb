{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb0d1f7-fdb4-48b6-9fcd-f7d9f579c99a",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e728b35-a6dd-4327-9715-8bfa8f5c5996",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83ce26c-3dfd-40e2-be26-4c8779413f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Union, List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996df80-8d54-4e82-bc40-61b2199a8304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>days_birth</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>home_phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occup_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "      <th>CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No job</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-13899202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F-11380247500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>19087</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M-19087450000.0Working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15088</td>\n",
       "      <td>2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F-15088202500.0Commercial associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>15037</td>\n",
       "      <td>2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F-15037157500.0State servant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  child_num  income_total  \\\n",
       "0           0      F   N       N          0      202500.0   \n",
       "1           1      F   N       Y          1      247500.0   \n",
       "2           2      M   Y       Y          0      450000.0   \n",
       "3           3      F   N       Y          0      202500.0   \n",
       "4           4      F   Y       Y          0      157500.0   \n",
       "\n",
       "            income_type                       edu_type     family_type  \\\n",
       "0  Commercial associate               Higher education         Married   \n",
       "1  Commercial associate  Secondary / secondary special  Civil marriage   \n",
       "2               Working               Higher education         Married   \n",
       "3  Commercial associate  Secondary / secondary special         Married   \n",
       "4         State servant               Higher education         Married   \n",
       "\n",
       "            house_type  days_birth  days_employed  work_phone  home_phone  \\\n",
       "0  Municipal apartment       13899           4709           0           0   \n",
       "1    House / apartment       11380           1540           0           0   \n",
       "2    House / apartment       19087           4434           0           1   \n",
       "3    House / apartment       15088           2092           0           1   \n",
       "4    House / apartment       15037           2105           0           0   \n",
       "\n",
       "   email   occup_type  family_size  begin_month  credit  \\\n",
       "0      0       No job          2.0            6     1.0   \n",
       "1      1     Laborers          3.0            5     1.0   \n",
       "2      0     Managers          2.0           22     2.0   \n",
       "3      0  Sales staff          2.0           37     0.0   \n",
       "4      0     Managers          2.0           26     2.0   \n",
       "\n",
       "                                  CODE  \n",
       "0  F-13899202500.0Commercial associate  \n",
       "1  F-11380247500.0Commercial associate  \n",
       "2               M-19087450000.0Working  \n",
       "3  F-15088202500.0Commercial associate  \n",
       "4         F-15037157500.0State servant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"../data/cleaned_train.csv\")\n",
    "test_df=pd.read_csv(\"../data/cleaned_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153ab41-bd52-4f6b-b942-bddacc461c0b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6beb9b5-1f99-43e7-95da-b1aa2e3f4984",
   "metadata": {},
   "source": [
    "### Numerical Data: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ecd7f4-7d09-4121-9beb-6a6113cc3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_data_scale(train_df, test_df, scaling_cols=None):\n",
    "    \n",
    "    scaling_cols = ['child_num','income_total','days_birth','days_employed','family_size','begin_month']\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "    train_scaled = std_scaler.transform(train_df[scaling_cols])\n",
    "    test_scaled = std_scaler.transform(test_df[scaling_cols]) # Apply to the test set using the scaler that was fitted with train data!!\n",
    "\n",
    "    train_scaled = pd.DataFrame(train_scaled, columns=scaling_cols)\n",
    "    test_scaled = pd.DataFrame(test_scaled, columns=scaling_cols)\n",
    "\n",
    "    train_scaled.shape, test_scaled.shape\n",
    "    \n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40509c9-b9a2-483e-b7de-2a42a47f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, test_scaled = num_data_scale(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7082e6-5b3b-47b5-836e-1fab433a3caa",
   "metadata": {},
   "source": [
    "### Categorical Data: One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdd30d0-5a85-48d5-8983-2fe166a18648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data_encode(train_df, test_df, onehot_cols=None):\n",
    "    \n",
    "    onehot_cols = ['gender','car','reality','income_type','edu_type','family_type','house_type','occup_type','work_phone','home_phone','email']\n",
    "    data = pd.concat([train_df[onehot_cols], test_df[onehot_cols]]) # One-hot encoding using the combination of train and test data\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    # data separation\n",
    "    data = data.reset_index(drop=True)\n",
    "    train_encoded = data.loc[:train_df.shape[0]-1]\n",
    "    test_encoded = data.loc[train_df.shape[0]:]\n",
    "    test_encoded = test_encoded.reset_index(drop=True)\n",
    "    \n",
    "    train_encoded.shape, test_encoded.shape\n",
    "    \n",
    "    return train_encoded, test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53b70e7-438a-4bab-bc0e-e58588a1eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = cat_data_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be44a5-9009-426b-85e3-794722ec960b",
   "metadata": {},
   "source": [
    "### Merge scaled numerical data with encoded categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f1fb29-0810-4ac7-b4d9-343a68ac191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded):\n",
    "    \n",
    "    Train = pd.concat([train_scaled,train_encoded],axis=1)\n",
    "    Train = pd.concat([Train,train_df['credit']],axis=1)\n",
    "\n",
    "    Test = pd.concat([test_scaled,test_encoded],axis=1)\n",
    "\n",
    "    Train.shape, Test.shape\n",
    "    \n",
    "    return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e80a91d-a145-46f8-810d-3c027739f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = merge_scaled_encoded(train_scaled, test_scaled, train_encoded, test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570651c1-6d02-483e-952c-90fabd5a5f7a",
   "metadata": {},
   "source": [
    "## Split Training and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4783507-8f94-4764-b221-a80c55f126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Train.drop(['credit'], axis=1)\n",
    "y = Train['credit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee27b2-f42e-4e40-9d35-e9dfac1a6d2a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb01c1-70b9-4f72-8a16-26c4e60c03b6",
   "metadata": {},
   "source": [
    "## Model Train\n",
    "\n",
    "**Among the tuned parameters or manual parameters tested by each team member, the one that produced better performance was selected.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38939327-4d09-41af-bf99-a6f3852020bb",
   "metadata": {},
   "source": [
    "# Catboost\n",
    "def stratified_kfold_cat(\n",
    "    params: Dict[str, Union[int, float, str, List[str]]],\n",
    "    n_fold: int,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    splits = folds.split(X, y)\n",
    "    cat_oof = np.zeros((X.shape[0], 3))\n",
    "    cat_preds = np.zeros((X_test.shape[0], 3))\n",
    "    cat_cols = [c for c in X.columns if X[c].dtypes == \"int64\"]\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"============ Fold {fold} ============\\n\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "        valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "        model.fit(\n",
    "            train_data,\n",
    "            eval_set=valid_data,\n",
    "            early_stopping_rounds=100,\n",
    "            use_best_model=True,\n",
    "            verbose=100,\n",
    "        )\n",
    "\n",
    "        cat_oof[valid_idx] = model.predict_proba(X_valid)\n",
    "        cat_preds += model.predict_proba(X_test) / n_fold\n",
    "\n",
    "    log_score = log_loss(y, cat_oof)\n",
    "    print(f\"Log Loss Score: {log_score:.5f}\\n\")\n",
    "    return cat_oof, cat_preds\n",
    "\n",
    "\n",
    "# LightGBM\n",
    "def stratified_kfold_lgbm(\n",
    "    params: Dict[str, Union[int, float, str]],\n",
    "    n_fold: int,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    splits = folds.split(X, y)\n",
    "    lgb_oof = np.zeros((X.shape[0], 3))\n",
    "    lgb_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"============ Fold {fold} ============\\n\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        pre_model = LGBMClassifier(**params)\n",
    "\n",
    "        pre_model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "        )\n",
    "        params2 = params.copy()\n",
    "        params2[\"learning_rate\"] = params[\"learning_rate\"] * 0.1\n",
    "\n",
    "        model = LGBMClassifier(**params2)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            init_model=pre_model,\n",
    "        )\n",
    "        lgb_oof[valid_idx] = model.predict_proba(X_valid)\n",
    "        lgb_preds += model.predict_proba(X_test) / n_fold\n",
    "\n",
    "    log_score = log_loss(y, lgb_oof)\n",
    "    print(f\"Log Loss Score: {log_score:.5f}\")\n",
    "\n",
    "    return lgb_oof, lgb_preds\n",
    "\n",
    "\n",
    "# SVM\n",
    "def stratified_kfold_svm(\n",
    "    params: Dict[str, Union[int, float, str]],\n",
    "    n_fold: int,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    splits = folds.split(X, y)\n",
    "    svm_oof = np.zeros((X.shape[0], 3))\n",
    "    svm_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"============ Fold {fold} ============\\n\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = SVC(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            #eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "            #early_stopping_rounds=100,\n",
    "            #verbose=100,\n",
    "        )\n",
    "\n",
    "        svm_oof[valid_idx] = model.predict_proba(X_valid)\n",
    "        svm_preds += model.predict_proba(X_test) / n_fold\n",
    "\n",
    "    log_score = log_loss(y, svm_oof)\n",
    "    print(f\"Log Loss Score: {log_score:.5f}\")\n",
    "\n",
    "    return svm_oof, svm_preds\n",
    "\n",
    "\n",
    "# Random Foreset\n",
    "def stratified_kfold_rf(\n",
    "    params: Dict[str, Union[int, float, str, bool]],\n",
    "    n_fold: int,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "    splits = folds.split(X, y)\n",
    "    rf_oof = np.zeros((X.shape[0], 3))\n",
    "    rf_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(splits):\n",
    "        print(f\"============ Fold {fold} ============\\n\")\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "        )\n",
    "\n",
    "        rf_oof[valid_idx] = model.predict_proba(X_valid)\n",
    "        rf_preds += model.predict_proba(X_test) / n_fold\n",
    "        print(f\"Log Loss Score: {log_loss(y_valid, rf_oof[valid_idx]):.5f}\")\n",
    "\n",
    "    log_score = log_loss(y, rf_oof)\n",
    "    print(f\"Log Loss Score: {log_score:.5f}\")\n",
    "\n",
    "    return rf_oof, rf_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e122b-c197-4c26-8b33-cdf52251d2f9",
   "metadata": {},
   "source": [
    "### LGBM Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c322d-8b3c-48f3-a6b3-8fd3548cb638",
   "metadata": {},
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "lgbm_oof, lgbm_preds = stratified_kfold_lgbm(lgbm_params, 10, X, y, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38194e81-82ed-4fc2-9afc-8e3ee08f0eb1",
   "metadata": {},
   "source": [
    "### SVM Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efac212-5508-4292-81ea-94c8a9f326e9",
   "metadata": {},
   "source": [
    "svm_params = {\n",
    "    'kernel' : 'rbf',\n",
    "    \"random_state\": 42,\n",
    "    'C' : 10.0,\n",
    "    'gamma' : 0.1,\n",
    "    'probability' : True,\n",
    "}\n",
    "\n",
    "svm_oof, svm_preds = stratified_kfold_svm(svm_params, 5, X, y, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f06368-91d9-4565-9162-525315c95eaa",
   "metadata": {},
   "source": [
    "### Random Forest Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbff840-fab4-44f9-9597-02709d26aef7",
   "metadata": {},
   "source": [
    "rf_params = {\n",
    "  \"criterion\": \"entropy\",\n",
    "  \"n_estimators\": 300,\n",
    "  \"min_samples_split\": 10,\n",
    "  \"min_samples_leaf\": 2,\n",
    "  \"max_features\": \"sqrt\",\n",
    "  \"oob_score\": True,\n",
    "  \"random_state\": 42,\n",
    "  \"n_jobs\": -1,\n",
    "  }\n",
    "\n",
    "rf_oof, rf_preds = stratified_kfold_rf(rf_params, 5, X, y, Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c9cfa9-ee2b-40ff-8e48-c838b7379917",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153fc6ac-84f9-4e1f-9be0-30efda3bb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'kernel' : 'rbf',\n",
    "    \"random_state\": 42,\n",
    "    'C' : 10.0,\n",
    "    'gamma' : 0.1,\n",
    "    'probability' : True,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "  \"criterion\": \"entropy\",\n",
    "  \"n_estimators\": 300,\n",
    "  \"min_samples_split\": 10,\n",
    "  \"min_samples_leaf\": 2,\n",
    "  \"max_features\": \"sqrt\",\n",
    "  \"oob_score\": True,\n",
    "  \"random_state\": 42,\n",
    "  \"n_jobs\": -1,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f6a501-660f-4af5-b0c4-1ca2ae41b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/3 [21:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[1;32m     36\u001b[0m names\u001b[38;5;241m.\u001b[39mappend(name)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (name, np\u001b[38;5;241m.\u001b[39mmean(scores), \u001b[43mstd\u001b[49m(scores)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'std' is not defined"
     ]
    }
   ],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('svc', SVC(**svc_params)))\n",
    "\t#level0.append(('rf', RandomForestClassifier(**rf_params)))\n",
    "\tlevel0.append(('lgb', LGBMClassifier(**lgbm_params)))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = CatBoostClassifier()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['svc'] = SVC(**svc_params)\n",
    "\t#models['rf'] = RandomForestClassifier(**rf_sparams)\n",
    "\tmodels['lgb'] = LGBMClassifier(**lgbm_params)\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_log_loss', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in tqdm(models.items()):\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e7698-f8cc-4ff3-baa6-69e7e3a88a9e",
   "metadata": {},
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
